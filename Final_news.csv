Date,Company,Title,Description,Link,Domain
30-07-2020,,Insurance broker Acrisure acquires Tulcos AI business to transform industry," Insurance brokerage firm Acrisure has acquired the artificial intelligence arm of alternative investing platform Tulco, in a move that aims to boost AI’s application in the insurance industry. The $400 million transaction is reportedly Acrisure’s largest ever deal, and adds to its catalog of more than 500 takeovers in recent times, as the broker develops technology for its business lines. Thomas Tull, the chairman and chief executive officer of Tulco, will become chairman of a new technology group at the brokerage. The acquisition builds on a year-long partnership between Acrisure and Tulco, which last year saw the creation of Altway Insurance, a fully-AI backed brokerage focused initially on individual health benefits. According to Acrisure CEO and founder Greg Williams, the deal will help the company lead the charge on AI within insurance. “Businesses that succeed in the medium to long term must be nimble, data-rich and digitally oriented,” said Williams in a statement. “The transaction with Thomas Tull and the Tulco team accelerates our ability to do all the above.” He added: “We’ve worked with the Tulco team for almost a year and our vision for Acrisure and the industry are completely aligned. Tulco’s world-class talent and ability to apply AI and intelligent automation is immeasurable as it relates to meeting the needs of our clients and transforming our company.” Acrisure has previously invested in robust data sets and internal analytics to better understand the risk needs of its clients, but having Tulco on board will help enable the deployment of new technologies in a wider context, bringing AI, data science and machine learning capabilities to the business. Indeed, AI and machine learning has been a source of great interest to both the insurance and wider financial industries in recent times. From behavioural policy pricing leveraging IoT tech, to fast customized claims settlements via virtual claims adjusters, AI is set to radically change the industry in coming years. Commenting on the acquisition, existing Tulco board member Jim Breyer noted, “The insurance sector is ripe for transformation and combining Tulco’s market-proven AI and data science products with Acrisure will deliver insurtech at scale.”",https://aibusiness.com/document.asp?doc_id=762823&site=aibusiness,Finance
27-07-2020,,"Royal Bank of Canada deploys a private cloud for AI with Nvidia, Red Hat"," Royal Bank of Canada (RBC) and Borealis AI partnered with Nvidia and Red Hat to create a computing platform for AI in banking. Borealis AI is a specialized research center established by RBC, Canada’s largest financial institution, in 2016. The center focuses on natural language processing, reinforcement learning, and responsible AI, to address challenges such as risk and fraud, and improve customer experience. The bank’s new dedicated AI cloud, powered by Nvidia’s DGX GPU-based servers and Red Hat’s OpenShift software, has the ability to run thousands of simulations and analyze millions of data points in a fraction of the time it previously took. “Modern AI cannot exist without access to high performance computing,” said Foteini Agrafioti, chief science officer, RBC, and head of Borealis AI. “This collaboration means that we can conduct research at scale and deploy machine learning applications in production with improved efficiency and speed to market.” Borealis AI intends to leverage the new infrastructure to create, deploy, and maintain AI-powered applications for personal and commercial banking, wealth management, and capital markets. “In today’s ever-changing marketplace, we must always be at the forefront of innovation for our clients,” said Mike Tardif, senior vice president, tech infrastructure, Royal Bank of Canada. “We are proud to have delivered a unique AI private cloud capability in-house, leveraging our strong collaboration with Red Hat and Nvidia. This cloud offers GPU acceleration and containerized platform benefits, and we are well positioned to provide the best experience possible for our customers going forward.” RBC said the new platform has improved trading execution and insights, helped reduce client calls, and allowed for faster delivery of new applications for clients, with the added potential to benefit the AI industry in Canada.",https://aibusiness.com/document.asp?doc_id=762709&site=aibusiness,Finance
27-07-2020,,Safehub gets $5m to predict damage from earthquakes," Shaking up the market A startup has raised $5m to help monitor the impact of earthquakes. California-based Safehub uses a network of distributed sensors to detect seismic events, and artificial intelligence to predict their effect on structures. This, the company says, can be useful not just for planning emergency response – but also for calculating financial loss estimates, including building damage and business interruption losses. The US suffers around 15 earthquakes per year with an average magnitude of 7 or greater – although there could always be a much larger event right around the corner. This amounts to an annual cost of $6.1 billion in building stock losses, according to a 2017 FEMA study. But the true number is likely higher, as the estimate does not include induced seismicity – where human activity causes earthquakes or tremors. “Our vision is a safer and more resilient world,” Andy Thompson, CEO of Safehub, said. “In the event of a natural disaster, organizations need timely and detailed information to get ahead of potential downtime and business interruption losses.” “With our platform, business continuity and emergency response professionals can understand the extent of the problem remotely, and prioritize damage assessments with building-specific data.” The funding round was co-led by Fusion Fund and Ubiquity Ventures. Bolt, Promus Ventures, Blackhorn Ventures, Maschmeyer Group Ventures, and Team Builder Ventures also participated. Safehub said that it plans to use the funds to accelerate deployment to Fortune 500 companies. “Software is leaping beyond the screen to solve more concrete business problems in the real world,” Sunil Nagaraj, managing partner of Ubiquity Ventures, said. ""Safehub uses smart hardware to help the largest companies in the world manage and monitor their buildings and offices to increase their resilience – a pain we are seeing magnified during COVID."" While its earthquake response service potentiality deals with the issue of human safety,  Safehub’s terms of service note that the company is “not responsible for any damages allegedly caused by the failure or delay of the Services. “In addition, you acknowledge that the Services, including remote access and mobile notifications, are not intended to be 100 percent reliable and 100 percent available.” Some of Safehub’s competitors go as far as to claim their AI systems can predict an earthquake a few minutes before it hits. In Mexico City, two years after a devastating earthquake, SkyAlert twice overstated the magnitude of upcoming earthquakes – the city's head of early warning systems told the Wall Street Journal this error caused tens of thousands of workers to leave work.",https://aibusiness.com/document.asp?doc_id=762694&site=aibusiness,Finance
19-07-2020,,Snorkel AI raises $15 million for end-to-end AI platform," California-based Snorkel AI, a startup spun out of the Stanford AI Lab, has raised $15 million in funding as it emerges out of stealth mode. The funding for Snorkel’s end-to-end machine learning platform came from Greylock, GV, and In-Q-Tel (the investment arm of the Central Intelligence Agency). The startup’s customers include US banks, large enterprises, and government agencies. Snorkel focuses on large training datasets, programmatically labeling and managing the training data that fuels AI models. For example, banks use the Snorkel Flow platform to build AI applications that classify and extract information from their loan portfolios. While at the Stanford AI Lab, the Snorkel founders developed technologies for training data that were used by companies including Google, Apple, and Intel. “Despite spending billions of dollars on AI, few organizations have been able to use it as widely and effectively as they want to,” said Alex Ratner, CEO of Snorkel AI. “Available solutions either ignore the most important part of AI today – the labeled training data that fuels modern approaches – or rely on armies of human labelwers to produce it. Snorkel Flow focuses on a new programmatic approach to the training data that enables enterprises to use AI where they couldn’t before.” Developers using the Snorkel Flow platform create ‘labeling functions,’ or rules, and other programmatic operators, which the platform automatically integrates to train machine learning models. Users then can then adapt the models by editing the programmatic training in Snorkel Flow’s interface. “We’ve consistently heard from Fortune 500 CIOs that they have been disappointed with their progress using AI, largely because they get stuck on the data,” said Saam Motamedi, partner at Greylock and Snorkel board member. “Customers’ rapid success with Snorkel Flow is a testament to the power of this new, data-centric approach, which has the potential to democratize AI across the enterprise.” Snorkel Flow has been used for a number of applications. For example, Google used the platform to replace hand-annotated labels in key machine learning pipelines, Intel used it to replace a high-cost, high-latency crowdsourcing pipeline to accelerate sales and marketing agents, and researchers at Stanford Medicine used Snorkel Flow to label medical imaging and monitoring datasets, replacing person-years of hand labeling. “The time, expertise, and costs involved in labeling training data present significant challenges to the US government in applying AI to missions of national security,” said A.J. Bertone, a partner at In-Q-Tel. “Snorkel AI provides a revolutionary capability that can greatly reduce the level of effort required to develop mission-ready machine learning models by addressing this critical data problem.”",https://aibusiness.com/document.asp?doc_id=762512&site=aibusiness,Finance
08-07-2020,,"Partnership on AI, Kodiak Robotics, Faraday Future, more take out PPP loans"," Silicon Valley libertarian mindset meets its limits Several artificial intelligence startups and foundations in the US have taken out Paycheck Protection Program loans. PPP was created as part of the $2 trillion CARES Act, aimed at retaining jobs during the COVID-19 pandemic and fighting its economic fallout. On the list of more than 660,000 companies that received more than $150,000 in loans was ‘the Partnership on AI to Benefit People and Society.’ The Partnership is a US-led alliance promoting the ethical development and deployment of AI technologies, and includes Amazon, Google, and Microsoft among its members, as well as Japanese companies like SoftBank and Sony, and South Korea's Samsung. With US-China relations souring, Chinese tech giant Baidu left last month. The group took out a loan of $350k-$1m, to help retain 29 jobs. The similarly named Artificial Intelligence Foundation took out roughly the same amount, saving 59 jobs. Despite the name, it is a for-profit business that has raised more than $10m to develop personalized, AI-based agents, including a ‘Digital Deepak’ Chopra. We downloaded Digital Deepak to ask what the company will use its PPP loan for, but were told to join a waiting list. The hard-science focused Noble Artificial Intelligence took out between $150k and $350k for 12 jobs. It develops AI for R&D, most recently offering free access to its platform to COVID-19 researchers. A number of self-driving vehicle startups and equipment suppliers also sought loans, including Pronto.ai, founded by Anthony Levandowski, who is awaiting sentencing for using Waymo trade secrets while employed at Uber. The company took out a loan of at least $350k for 17 jobs. With $1m-$2m in loans, autonomous trucking company Kodiak Robotics plans to keep 87 jobs. TuSimple, another self-driving trucking company, will keep 324 jobs thanks to a loan of between $2m and $5m. In June, TechCrunch reported that the company had hired investment bank Morgan Stanley to help it raise an additional $250 million from investors. Last week, TuSimple announced that it had teamed up with UPS, Xpress Enterprises, Penske Truck Leasing, and Berkshire Hathaway-owned grocery and food-service distributor McLane to build a coast-to-coast autonomous trucking network. Electric car company Faraday Future, which has self-driving ambitions, loaned $5m-$10m for 237 jobs. It has long struggled – we profiled its complicated journey in May. Chinese EV startups Byton, Nio, and Karma Automotive were also in favor of PPP loans – each getting between $5m and $10m. Byton, which furloughed hundreds of employees in April, said it would use the money to keep 387 jobs. But last week it announced it would stop operations for at least six months, and laid off North American workers. Nio, which reduced its headcount last year, said it would save 204 US jobs with the loan. In June, a local government in Hefei, China, provided it with a $1bn bailout package. Karma Automotive, which emerged out of the bankrupt 'Tesla Killer' Fisker, said it would keep 463 jobs thanks to the loan. It also went through multiple layoff rounds last year. Chinese automotive startups Saleen and Mullen Technologies, as well as the US research and development center of Chinese state-owned automaker Chang’an Automobile, all received between $350k and $1 million. Bluespace.ai, which wants to build autonomous driving systems for mass transit and raised $3.5m in December, received at least $150k to save five jobs. Loaning the same amount was driver assistance app Comma.AI. Then comes Velodyne, which builds the majority of the LiDAR sensors that help self-driving cars understand their environment. It took out a $5m-10m loan for 450 jobs. In the same loan bracket was its rival LiDAR developer Luminar, which will retain 341 jobs. Engineer.ai took out $1m-$2m to save 38 jobs. It claims to have created an artificial intelligence-assisted app development platform, raising nearly $30m from SoftBank. But a 2019 Wall Street Journal report uncovered that humans still did most of the work, with AI functionality heavily overstated. That year, its chief business officer Robert Holdheim sued the company for misleading investors. AI-based virtual assistant specialist Kore.ai received between $350k and $1m for 33 jobs. Enterprise artificial intelligence company Semantic AI took a loan out for $1m-$2m, saving 55 jobs. Another small business, Landing AI, received $350,000-$1m for an undisclosed number of jobs. AbsolutData, an enterprise AI firm unrelated to the vodka brand, took out $350k-$1m for 65 jobs. For the same amount, AI-powered enterprise data transparency and monetization platform Helios Data retained 15 jobs. ‘Cognitive’ supply chain management company LevaData joined the $350k-$1m club, saving 24 jobs. Nimble Data Technologies (not to be confused with the storage company) borrowed $150k-$350k for 17 jobs. Operating under the name Crest Data Systems, it develops AI and orchestration tools for businesses. Robust AI, which hopes to build an industrial-grade cognitive platform for robots, took out a $150k-$350k loan for 11 jobs. It previously received an investment from Playground Global, a venture fund established by Andy Rubin – but the Android creator's involvement has since been downplayed due to sexual harassment allegations while he was at Google. Autonomous robot company Tomahawk Robotics took out $350k-$1m for 21 jobs. Conversational search engine Searchable.ai, which is yet to launch a product off the back of a $4m funding round in June, took out a loan of $150k-$350k for seven jobs. Zenabi Data, which claims its AI can improve everything from fraud detection to supply chains, loaned $350k-$1m. VEDA Data Solutions, which uses AI on healthcare directories, raised $5m in December. A few months later it took out a PPP loan of $150k-$350k to save 19 jobs. Rekall.ai, a company so vague AI Business could not ascertain exactly what they do (although it's something to do with crypto), received $150k-$350k for 12 jobs. Document, invoice, and loan processing company SoftWorks AI took out a loan of its own. It saved 19 jobs for $150k-$350k. Encrypted traffic security company CounterFlow AI also took out at least $150k, saving 14 jobs. Wave Computing took out a huge $2m-$5m loan for just 29 jobs at the end of April – two days after it filed for bankruptcy. The once-promising AI processor company lost its CEO in December, and has struggled with high debt. Federal officials claim that the $521 billion in PPP loans supported over 51 million jobs nationwide.",https://aibusiness.com/document.asp?doc_id=762264&site=aibusiness,Finance
03-07-2020,,PwC partners with Cleareye.ai for new banking products," California-based Cleareye.ai has signed a joint business relationship agreement with PwC to develop and provide unique products to the banking industry. As part of the deal, PwC gains access to the Cleareye.ai platform and the range of products and solutions the company markets to its banking customers around the world. The platform provides conversational AI assistants and products for fraud detection and monitoring, third-party risk assessment and monitoring, and trade finance sanctions screening in the US, Europe, and India. The Cleareye.ai platform combines consumer experience sensing, insights generated from data, and AI-powered automation. ""PwC's partnership with Cleareye.ai evolved at a rapid pace, fueled by an increasing demand for AI-powered solutions from our customers,” said Liviu Chirita, partner and joint business relationship lead at PwC. “With our partners, we have an agile and agnostic approach to building such solutions, characterized by our ambition to create an asset-based consulting experience that is expertise-driven and technology-enabled.” The initial focus of the venture will be on regulatory compliance. “In regulatory compliance, we focus on increasing risk coverage and productivity while decreasing the cost of compliance,"" Chirita said. ""This collaboration is uniquely positioned to help our financial services clients tap into the consulting and subject matter expertise of PwC and technology depth and problem-solving abilities of Cleareye.ai,” added Mariya George, Cleareye.ai's president and co-founder. In May, Cleareye.ai acquired India-based startup Aiware.ai, which specializes in conversational tech, credit risk analytics and AI consulting, to further its efforts to sell artificial intelligence to banks.",https://aibusiness.com/document.asp?doc_id=762172&site=aibusiness,Finance
01-07-2020,,Hi Marley raises $8 million to develop conversational AI for insurance," The platform allows claims, underwriting and policy interactions by text Hi Marley, a startup specializing in AI-based conversation tech for the insurance industry, has closed an $8 million funding round. The Series A1 round brings the Boston-based company’s total financing to $18 million. The money will be spent on refining Hi Marley’s insurance focused conversational messaging product and increasing customer engagement, according to the company. The funding found was led by True Ventures and Underscore VC, with participation by Bain Capital Ventures and Greenspring Associates. “Hi Marley is solving a fundamental problem with the way insurance carriers interact with their insureds,” said Puneet Agarwal, partner at True Ventures. “We value the existing partnership with Underscore VC and True Ventures and welcome our new partners at Bain Capital Ventures and Greenspring,” said Mike Greene, founder and CEO of Hi Marley. “We’re grateful to have investors who appreciate the insurance industry and are aligned with the purpose and vision we share with our customers.” Hi Marley’s intelligent, text-based messaging platform is used by insurance companies and their partners to connect with customers for transactions across claims, service, and underwriting. For example, the system can be used to notify customers of premium relief credits and billing options relating to the global pandemic. The Hi Marley AI platform, launched in 2017, is used by insurers including American Family and Plymouth Rock. “The Hi Marley platform is helping our insurance business level-up to, and even exceed, the expectations of our customers that are used to mobile-enabled experience in most other aspects of their life,” said Mary Boyd, president and CEO, Plymouth Rock Assurance. “Combining Hi Marley’s technology and the Plymouth Rock brand of uniquely human service, we are delivering proof that by meeting customers where they are and offering satisfying service, we can build a stronger business.” The new funding is expected to allow the expansion of the engineering team to accelerate certain industry features and grow the customer-facing teams to deal with market demand. Hi Marley also plans to build out its portfolio of APIs and increase partnerships with other industry platforms.",https://aibusiness.com/document.asp?doc_id=762121&site=aibusiness,Finance
25-06-2020,,Deloitte launches AI Institute to advance innovation in the enterprise," Professional services giant Deloitte has launched a center for applied artificial intelligence. The AI Institute is set to focus on using cutting-edge research to address real-world enterprise use cases. “Our goal is to blend Deloitte's deep experience in applied AI with a robust network of some of the most intelligent AI minds in the world to challenge the status quo,” said Nitin Mittal, AI co-leader and principal at Deloitte. “We aim to deliver impactful and game-changing research and innovation where humans work side-by-side with machines."" Mittal was named AI Innovator of the Year at the AI Summit New York in November 2019. Deloitte AI Institute hopes to recruit thought leaders, academic experts, startups, research and development groups, entrepreneurs, investors, and innovators to bolster its network. “This network of specialists and research, combined with Deloitte's depth of applied AI knowledge and understanding of pain points across industries and sectors — whether identifying use cases, understanding industry specific ecosystems, scaling from AI proof-of-concepts, or securing AI systems — can help organizations transform quickly with AI,” the company said in a statement. To develop ethical safeguards, the new center plans to collaborate with leading ethicists. ""With AI ethics, the Institute aims to help organizations achieve a positive future by bringing together top stakeholders from all sectors of society to discuss and co-design effective policies and frameworks, such as Deloitte's Trustworthy AI framework, for governing AI,"" said Irfan Saif, prinncipal at Deloitte Risk & Financial Advisory, and AI co-leader. To help enterprises move forward with AI, the institute aims to help organizations “remain distinctively human in a technology-driven world.” Click here to watch our interview with Deloitte’s Nittin Mittal at the AI Summit New York.",https://aibusiness.com/document.asp?doc_id=761990&site=aibusiness,Finance
11-06-2020,,New COVID-19 norms drive AI deals following record 2019 ," The number of mergers and acquisitions involving AI firms reached 279 in 2019, more than all the AI deals in 2017 and 2018 combined, according to a new study by Hampleton Partners. Despite the global pandemic, a further 95 M&A deals were recorded in the first quarter of 2020, with forecasts showing that the total could rise to the peak seen in the second half of 2019. “The arrival of Covid-19 is putting artificial intelligence innovators and companies further in the spotlight for strategic buyers,” said Heiko Garrelfs, sector principal at Hampleton Partners. “New norms such as health checks and social distancing at work are driving AI adoption and adaptation.” By volume, Apple made the most (10) AI-related acquisitions in the last 30 months, followed by Microsoft, Accenture and Oracle, with five each, and VMware, Facebook and ServiceNow, with four each. AI used for quantitative analysis accounted for 70 percent of all AI deals between May 2019 and May 2020. The largest AI deals included Thoma Bravo’s take-private of anti-malware company Sophos for $3.8 billion, the acquisition of Assurance IQ’s ML-based insurance search service by Prudential Financial for $2.4 billion and Hewlett Packard’s purchase of Cray’s high-performance computing technology for $1.4 billion. Healthcare, automotive and financial services are the sectors with the greatest potential for disruption by AI, according to Hampleton. Improvements in financial services, such as personalized financial planning, fraud detection and process automation, are seen as fueling AI adoption.",https://aibusiness.com/document.asp?doc_id=761653&site=aibusiness,Finance
03-06-2020,,Russian bank launches AI-based financial assistant named after Warren Buffet ," TalkBank, Russia’s first ’in-messenger’ virtual bank – with no offices or mobile apps – has launched an AI-powered virtual assistant, named after famed investor and business tycoon Warren Buffet. Buffet, the assistant, integrates into customers’ messenger apps to coach them on how to better handle their personal finances. Buffet gains access to client activities via the TalkBank platform and then applies artificial intelligence models to analyze spending patterns, coming up with recommendations on ways to spend smarter and increase savings. The bot is available via Facebook Messenger, WhatsApp, Viber, VK and Telegram and is able to answer questions posed in natural language. Buffet’s features include the ability to calculate monthly income and expenses, provide current information on exchange rates, remind about loan payments and help with planning a budget, setting financial goals or obtaining optimal travel insurance. As is typical with AI-based software, Buffet is able to learn as customers interact with it. The chatbot can be activated by contacting TalkBank in one of the five supported platforms by sending the message “hi.” Internal operations at TalkBank are also carried out with the help of AI systems, by chatbots that help customers apply for, and receive, bank cards, and transfer money online.",https://aibusiness.com/document.asp?doc_id=761467&site=aibusiness,Finance
27-05-2020,,US fintech Cleareye.ai acquires India's Aiware.ai," Acquisition.ai   California-based Cleareye.ai has acquired Aiware.ai to help further its efforts to sell artificial intelligence to banks.   The Indian startup will be renamed Cleareye.ai India Pvt Ltd, serving as the dedicated product development and R&D division of the company. 
 The Kerala-based office is set to add around 100 staff in domains like data science and artificial intelligence.     ""We marry customer experience and risk management for banks to simplify their operations and increase top line and bottom line growth through our outcomes-driven platform, which can be readily integrated with the banks' existing systems at little incremental cost and minimal disruption to existing technology footprint,"" Sarath Sasikumar, co-founder and chief program officer at Cleareye.ai, said.   The company's primary focus is on virtual assistants that provide financial advice, sentiment mining, fraud detection, and other banking-related functionality.   The combined forces of our team in India and the global company will strengthen our ability to offer unique solutions leveraging artificial intelligence, bionic automation, and advanced analytics, Chandrasekhar Somasekhar, chief architect at Aiware.ai, said.    The company previously sold its solutions to  Cleareye.ai, including ConverseWare, a banking conversation tool, as well as credit risk analytics and AI consulting.   ""We are incredibly excited about our journey ahead and are looking forward to exploring the wide opportunities this union will bring, AIWare.ai COO Sachith Sebastian said. Juniper Research reported that AI-powered chatbots alone saved banks $127m in costs in 2019.   Juniper Research recently reported that AI-powered chatbots alone saved banks $127 million in costs in 2019. ",https://aibusiness.com/document.asp?doc_id=761339&site=aibusiness,Finance
27-05-2020,,AI-powered chatbots saved banks $127m in 2019," More expensive call centers = more savings with AI   Chatbots are saving businesses money, but no other industry has benefited from this tech as much as banking, according to Juniper Research.  
The analyst firm estimates that savings of $165 million were enabled by chatbots in 2019, with the banking sector responsible for 77% of the total.   Large cost savings in the banking sector are predominantly caused by the comparatively higher costs relating to customer service operations, states the Juniper study.  
Rather than outsourcing call centers abroad, banks have sought to improve customer loyalty by hosting customer service advisors in native call centers, thus increasing the cost due to higher wages.     Juniper defines a chatbot as a computer program utilizing technology designed to simulate conversational interactions with human users, which may also include automated processes triggered from these interactions.   The three main types of chatbots are app-based, web-based, and those on popular messaging platforms.   In time, chatbots could become sophisticated enough to complete a range of complex tasks on behalf of a person without any assistance from human agents, according to Juniper.   The total number of chatbot interactions in 2019 passed four billion, generating retail spending estimated at $2.8 billion.   Far East and China accounted for 88% of the total spend from chatbot transactions. More than $80 billion is projected to be spent via chatbots in China in 2024.   In addition to banking, the retail sector is expected to benefit from advances in natural language understanding (NLU), which can enable chatbots to more appropriately process human interactions, with accurate, automated responses.   More than 50% of retail chatbot interactions are expected to be completed without human intervention by 2024.   Two-thirds of consumers surveyed in 2018 said that an AI-powered chatbot would be useful in assisting them and 44% would rather communicate with a chatbot than a real person.   Chatbots also are being deployed for applications outside customer service. For example, the Development Bank of Singapore used chatbot technology to streamline its job application process. The AI-based system helped perform the assessment of a candidates resume in eight minutes compared to the 30-minute manual process, according to the bank.   Financial institutions are not alone in turning to AI-powered chatbots to aid in customer interactions.   Amazon has been testing neural-network-based automated chat systems to automatically deal with common customer service requests and help customer service agents, as detailed earlier this year by Chain Store Age. ",https://aibusiness.com/document.asp?doc_id=761338&site=aibusiness,Finance
21-05-2020,,"Gartner names cool vendors in AI for banking, investment services"," Four companies are making waves in the hotly contested market   Banking and investment businesses are increasingly turning to AI software to optimize their operations, and a recent report from Gartner shines a light on several vendors providing this tech.   The majority (53%) of financial institutions are employing AI methods to foster new thinking and disrupt business models, the firm said, as it identified four tech suppliers as Cool Vendors in AI for Banking and Investment Services.     The Cool Vendors offer solutions that target direct capital market and asset management operations or solutions that can enhance delivery of products and services to the customers, according to Gartner.   They leverage AI technologies, such as deep learning, natural language processing and predictive analytics with the goal of reducing cost, increasing revenue or improving customer experience.   Such AI solutions can help with risk management, optimizing operations and improving decision making.   For example, Socure uses machine learning to improve risk management by analyzing information from thousands of disparate data sources in real time.   By utilizing advanced data science and machine learning techniques, we are able to improve the overall identity verification performance and user experience, said Tom Thimot, CEO of Socure, which is in use by more than 200 banks, lenders and payment providers globally.   Eigen Technologies, another cool vendor, uses its natural language platform to provide clients with self-service data extraction and analysis. The platform aims to help organizations improve operational efficiency by using the banks internal data.   Axyon AIs products focus on benchmarking, managing risk and meeting positive client returns. The company leverages deep learning for client support in asset management and capital markets.   The fourth 'cool vendor,' Tenspace, analyzes social media using AI-based tools to improve decision making for three scenarios: credit scoring, lending, and anti-money laundering.   Artificial intelligence and machine learning were ranked as the top game-changing technologies in financial services, according to the 2020 Gartner CIO Survey.   Following AI (27%) were data analytics (26%), cloud computing (24%), APIs (18%), digital transformation (14%) and operation process technologies (8%).   Back in 2019, Gartners AI in Organizations survey found that the majority (56%) of financial services executives saw AI as a way to optimize their current processes.   Gartner has published its Cool Vendor research since 2004 across nearly 100 different market areas, including retail, data science and analytics, typically highlighting lesser-known, emerging vendors. The criteria for naming the cool companies, nominated by Gartner analysts, includes being innovative, impactful and intriguing.   Gartner makes three recommendations for banking and investment services looking to deploy AI-based tools for their business:     Gartner does not officially endorse its cool vendors, and always adds a disclaimer about evaluating their fitness for a particular purpose. But, if nothing else, the cool vendors earn serious bragging rights. ",https://aibusiness.com/document.asp?doc_id=761321&site=aibusiness,Finance
05-05-2020,,The disruptive influence of FinTech in data centers," by Spencer Lamb, KAO Data 5 May 2020   The last 40 years have seen more change in the financial trading sector than the previous 140. The 1980s witnessed a new breed of salesmen on the trading floors, while the deregulation of the 1986 big bang changed stock markets around the world.   There are many myths around the perceived secrets to success within this markets innovative processes.  
They include the legend of location, where companies have built trading offices close to landfall sites for ultra-low latency international connectivity links, in order to gain valuable milliseconds on trades.   There are whispers regarding technologies, such as in the early 2000s, where arrays of programmable logic supported the fastest processors, which ran parallel and computational intensive processing and dramatically increased the capabilities for early algorithm-based trading systems. In hindsight, its no small wonder that Intel purchased Altera, the field-programmable gate array (FPGA) manufacturer, for over $16 billion in 2015.   Each of these illustrates this industrys urgent need for resilient, high performance computing (HPC) systems that operate with minimum latency, delivering immense computational power and data storage capabilities that maximize and enable profitable trades and investments. However, for many Artificial Intelligence (AI), has had what can only be described as a game-changing impact.     Today, conferences such as NIPS and the AI Summit have fast become Meccas for the global AI industry. For many, joining these events offers direct access to new HPC technologies, expert consultants, manufacturers and data scientists; those who not only understand the convergence of software and hardware in FinTech, but who can collaborate to unlock the next phase of profitable growth. To put it bluntly, banks and Hedge Funds are now ready to put their money where their mouth is, investing in people and machine learning technologies to gain a competitive edge in the financial arena. According to a new research report from Omdia, the financial services industry will be responsible for 10 percent of all spending on AI software and by 2025, the market could be worth around $126 billion. This is a significant increase from 2018 where the estimated market value was around $10.1 billion. There are many cost savings directly enabled via deploying new technologies, and according to Business Insider Intelligence, AI applications could save banks as much as $447 billion by 2023.   AI requires IT workloads unlike anything that financial organizations have seen before. The combination of big data, AI and machine learning to evaluate investment opportunities and optimize trading portfolios, whilst mitigating risks, are changing quantitative data analysis techniques.   Therefore the design of the HPC infrastructure required to undertake this level of analysis is one that has to be underpinned by next-generation data center infrastructure.   Today, machine-learning models are used for credit decisions, to predict risk, to analyze contracts and within both fraud detection and Anti-Money Laundering (AML) initiatives. Algorithmic trading, of course, hasn't gone away, according to Seeking Alpha, by the start of 2019, 80 percent of the daily fluctuations in US stocks were machine-led. New hardware systems, tools and technologies are therefore constantly in development to support faster and more accurate decision-making.   Infrastructure systems today have access to millions of data points collected in many different formats. They include structured, semi-structured and unstructured data. Larger datasets taking into context stock prices, company statements, earnings reports, economic indicators, in addition to data generated via non-traditional sources like social media, web traffic and news platforms, now offer the ability to contextualize a more complete picture and deliver far better trading decisions.   The systems aggregating and processing this level of complexity are helping to determine what information is important and indicate where trends or change in sentiment may generate new financial opportunity.     Most AI-based products are powered by machine learning models and involve two stages of development: training and inference. Inference is the simpler of the two and can be done on edge computing devices  take the input, run it through the model, and get your results. In contrast, training, the process of generating the model from scratch using example data, requires massive amounts of storage and compute power, which often means the need for a data center.   In extreme cases  major language models that power some of the most popular online services can require petabytes of data and hundreds of kilowatts of power to generate more-accurate results. System training workloads also need parallelism, which means cores, and lots of them. Targeting a training workload at a traditional CPU with up to 64 cores will produce a result, but there are far superior ways to do this.   The trend for parallelism, for example, has revitalized the GPU, which now offers thousands of compute cores onboard single chips and has made Nvidia a perennial investors favorite.   Where there is profit there will always be competition, and the size of the prize caused an explosion in new chip architectures from startups like Graphcore, Ampere and Cerebras. Meanwhile semiconductor veteran Xilinx has reimagined its FPGA technology for the needs of machine learning, with the adaptive compute acceleration platform (ACAP).     What unites all of this new IT capability is its power requirement and the ability to remove the heat in a safe and efficient process. Legacy data centers using chilled air to cool the technology suite are not designed to maximize the operation of AI servers and will often require completely different cooling infrastructures, involving a large investment in upgrades or retrofit.   New AI server architectures, with an average power usage of 30+ kW per rack, require specific cooling strategies that only the latest data center designs are capable of accommodating and for the end-user, customization in design is key to anticipating their ever-changing needs.   Liquid cooling, for example, requires infrastructure that contradicts the old data center premise that water and servers should never meet. What we are witnessing is a massive increase in compute density, which again creates other pressures. The power that facilities can operate within was previously designed based on a nominal server/rack energy usage, yet AI-servers are changing power utilization across site.   Water-cooled processing also means new rack and enclosure architectures, which are evolving away from air-cooled cabinets and indeed many legacy data centers are not engineered to accommodate the floor weight loading that AI-racks require.   Overall, providing the infrastructure that supports AI and ML workloads requires a different approach to design, to cooling and a reputation for technical excellence. For this reason, banks are frequent guests at industry events. Partnerships with the developers and users is essential as AI and machine learning projects are complex, not only because they require a particular set of data, software and skills, but they also need businesses to implement and support ever-changing types of hardware.   Although innovation in the sector is a constant, designing and building the structures to accommodate the latest software requires customizable architectures, built to the latest specifications such as OCP (Open Compute Project) and which remain highly scalable to meet the demands of AI and HPC.   Today, Kao Data has been founded with the expertise to design and build bespoke and enterprise-scale data centers with outrageous power densities. It offers businesses from London and further across the UK Innovation Corridor towards Stanstead and Cambridge, the first generation of facilities suitable for hyperscale-level machine learning on an industrial scale.   The technological requirements in Financial Services are driving innovation in colocation. Yet for these organizations, a data center is not just a secure home for their servers. Through collaboration, partnership and technical excellence they now offer strategic capacity, 100% uptime and scalability, enabling ultra-fast AI processing and highly profitable financial transactions.    Spencer Lamb is VP of Sales and Marketing at KAO Data, a data center campus located near London. ",https://aibusiness.com/author.asp?section_id=789&doc_id=761293,Finance
29-04-2020,,How banking benefits from AI and voice technology," Banks are implementing machine and deep learning capabilities to improve and learn from customer experiences, offer conversational banking, and enable the next generation of investors   by Rana Gujral, Behavioral Signals 29 April 2020   From the implementation of self-serve ATMs in the 1960s to the widespread use of computers in the late 1970s and early 1980s, Fintech has always been the cutting edge space for innovation that directly impacts the consumer.   Its no surprise then that the banking industry spent nearly $30 billion on data and business analytics tools and software in 2019. Business Insider Intelligence estimates that banks can save as much as $447 billion through artificial intelligence by 2023, by using it for customer service, anti-fraud efforts, and underwriting support. Additionally, banks have been cited to use AI tech far more than many other industry, with 75% of banks already doing this to some degree.   Its the consumer-side of banking that presents the greatest opportunity for AI integration, however. With upwards of $200 million in potential cost savings, banks are leveraging AI tools to measure and improve the customer experience, and offering robo-advisory tools to help new investors jump into the stock market. Lets take a closer look at these use cases and the role that AI and voice play in the banking industry.     Consumers have come to expect a highly personal experience that is specific to their needs. At scale, this is difficult to deliver with human operators alone. The consistency of service is variable, and the ability to handle complex problems in real-time is limited.   Voice technology is leading the way in improving this experience and augmenting human customer service agents to be better at their jobs. In addition to processing millions of transactions and customer interactions every day, banks are now also able to evaluate customer voice data in real-time to identify their behavioral patterns in order to best match customers with agents to achieve desired results. This technology will be essential to not only speed up the process to improve real-time efficacy, but also provide better support and customer satisfaction when faced with such challenges as debt payments and loans. When the right customer is matched with the right customer service agent, not only will the interaction be optimized to produce the desired result on both ends, it will also lead to higher satisfaction from both client and employee.   Behavioral prediction algorithms are able to identify potential issues based on the customers voice patterns, the cadence of their speech, and their past behavior on previous calls. Emotion AI can identify when someone grows upset and route them to the correct agent proactively. Similarly, the system can provide real-time instructions and recommendations to the customer service agent to address challenges as they arise.   AI is also being used to predict purchasing and payment behavior. This can help inform credit decisions, provide better fraud detection services that are more proactive, but accurate enough to avoid disrupting a consumers card usage, and much more.     Banks have been pushing customers towards digital solutions; it's been more than twenty years since the first online banking websites launched. As customers have grown more comfortable with their smartphones, mobile banking has taken hold as the preferred means by which most consumers deposit checks, check balances, and make inquiries. AI is helping in the form of conversational banking.   Chatbots are able to perform a range of tasks that once required a human operator, including checking balances and answering frequent questions. AI makes it possible to provide a more personalized experience for all customers. Customers who are traveling for work and have a transaction declined can be quickly routed to the appropriate agent who will have access to their information in advance. Customers who are angry can be evaluated by an emotion AI agent, which can provide escalation recommendations to an agent to address the problem before it grows.   Banking is one of the truly omnichannel experiences in American life, but today, almost 75% of all bank transactions being done online. That can create a disconnect when a customer does visit a branch. AI tools can provide valuable insights both to phone agents and bankers to maintain consistency across all transactions.     Investing traditionally was not easy. It required a fair amount of initial capital, a large amount of data, and the time to invest. The only real way to engage with the stock market was through a financial advisor who held onto data with an iron grip. Those same advisors, however, frequently would decline small net-worth clients, severely limiting the options most people had if they wanted to invest.   AI systems are democratizing data and making it possible for more people at different stages in their lives to invest in the stock market, with the right insights. Tools like Betterment enable clients to sign up, signal their preferences and allow the AI system to invest on their behalf. The apps are programmed to capture key factors like overall investment goals, retirement plans, risk tolerance and more; such systems benefit from the fact that more than 90% of trades in some markets are now made by computers.   Not only do robo-advisors provide the data and insights that new investors need to participate in the market, despite a small portfolio; they do it often at less than 10% of the fee that traditional advisors charge.   Were still in the early days of robo-advisors and AI-driven trading for consumers, but by 2022, Business Insider Intelligence estimates that these tools will be responsible for more than $4.6 trillion in assets.     AI is being implemented across the financial industry. From back-end functions that influence a banks fundamental operations - how it distributes credit and monitors transactions - to front-end customer service and product offerings, AI is helping to improve the user experience.   By utilizing chatbots online and voice assistant technology over the phone, banks are able to develop stronger relationships with customers and a seamless experience across all levels of the bank - whether at an ATM while on vacation, or on the phone after a transaction is declined. This level of integration is helping the financial industry offer better, more personalized experiences, streamline productivity and grow their offerings without sacrificing quality at any stage of the process.    Rana Gujral is the CEO at Behavioral Signals, an emotion and behavior recognition software company. ",https://aibusiness.com/document.asp?doc_id=761287&site=aibusiness,Finance
04-03-2020,,Intelligent Automation: The key to fighting financial crime?," by Guy Matthews   John Sabatini leads the Americas Anti-Money Laundering (AML) team at PwC. For the past fifteen years, he has focused on financial crime and anti-bribery.
Today, John is responsible for multiple financial crime units that aspire to combine business knowledge with new IA technologies to make AML processes run more efficiently and productively. 
Today, John is responsible for multiple financial crime units that aspire to combine business knowledge with new IA technologies to make AML processes run more efficiently and productively.   AIB: How are banks keeping up with the modern financial crime landscape?   JS: Weve seen the market change really rapidly over the last couple of years. This is a high-spend area for banks, and theyve recognized over the last three or four years that throwing bodies at this problem is completely unsustainable. Some banks were spending hundreds of millions of dollars on growing AML teams, and now they have really started investing in automation, AI, and more thoughtful ways of doing things.   AIB: What are the key aspects of AI that PwC is investing in?   JS: Weve invested in three key areas of automation and AI. Digitizing the investigative procedures was our first step. Here, weve focused on focal entity consolidation  aggregating customer activity across accounts so we can see it all at once. Then, theres network analytics. There are a lot of common networks, payments, and relationships that investigators spend a tremendous amount of time trying to piece together. Today, you can make maps of recurring payments and transactions without having to do it from scratch every time, and therefore speed up decision-making. Finally, there are common fact patterns (CFP). Once youve investigated someone and youve come to a resolution, you can identify a CFP, and if nothing has substantially changed in the relationships or the activity, you dont need to do the work all over again  thanks to automation.   The second area involves designing more intelligent models. Here, weve aimed to bring some of the common investigative procedures into the monitoring models themselves, so the models can produce more effective, intelligent alerts based on the results of prior investigations and common relationships in the data.   The third area is dynamic KYC (know-your-customer) modelling. We use AI and automation to modify the customer risk scoring model to ensure outliers are identified and properly scored within the model.   AIB: Does automation impact business culture?   JS: Many financial institutions have developed a culture of empire-building around investigation teams. What were seeing now instead is companies building sustainable programs that leverage the latest automation and AI technologies to improve quality, use teams more efficiently, and reduce the number of staff. By reducing the amount of highly repetitive manual activity, firms are able to keep their most talented people reviewing more complicated cases, and use automation to do things more consistently. There is some cultural resistance to this, with a lot of concern around people being replaced by bots  but the overall aim is to make investigation teams more efficient, not obsolete.   Then, theres the benefit of timeliness. An activity which previously took four hours to complete can now be done in just two, thanks to automation. Everybody on the team is happy, and the output quality is good. Well go back, and the same person has still taken four hours, because people are used to taking that amount of time  they plan their day around doing one case in the morning and one in the afternoon.   You really need to implement effective management and governance to ensure that culturally, financial crime teams feel more comfortable with automation. Our approach involves educating people on how machines augment human decisions, rather than replace employees.   AIB: What are some of the issues caused by legacy systems?   JS: There are data issues in three different areas. Firstly, theres a whole host of problems around reliability of customer data. Theres information that could be years old that may have changed over time without being corrected.   Secondly, theres the challenge of aggregating information across silos. There could be really good information filled with inconsistencies. As you collect individual datapoints, through something like focal entity consolidation, youll see a lot of disparity in the data that needs to be reconciled.   Finally, even in transactional data, there are a lot of missing pieces. Many payment networks out there may not require specific information to process a transaction. There may be some data on the originator, but very little information on the beneficiary. What were seeing a lot of companies do today is force correspondent banks to provide that information. Instead of just processing consumer data, compliance officers should be processing transactions on the condition that proper monitoring of the necessary information is carried out.   AIB: What's one advice you would give to someone starting with AML automation?   JS: Everyone is trying to fix the entire data collection process before applying automation to it, but thats where they fail  theyre taking on too much. Instead, you need to start looking at the very repetitive processes that are using a lot of time and labor (what I call the major muscle groups), isolate them, then identify the points of automation. Weve seen this bottom-up approach being much more successful. If you try coming at AML from the perspective of a technology looking for a solution, well, weve seen that fail repeatedly.      This interview is part of Your Intelligent Automation Journey, an AI Business eBook produced in partnership with WorkFusion.    To receive your free copy of the eBook, please fill in the form below.  ",https://aibusiness.com/author.asp?section_id=789&doc_id=761231,Finance
03-03-2020,,AI: The digital with a difference," by James Buckley, Infosys Finacle 2 March 2020   A leading global market intelligence and advisory services firm predicts worldwide spending on Artificial Intelligence (AI) technologies to grow sharply from US$37.5 billion in 2019 to US$97.9 billion in 2023.    This money is expected to yield a fourfold benefit of about US$450 billion in cost savings over the next couple of years, according to another source.    Banks, along with the retail industry, top the list with projected investments of US$5 billion each (out of the total US$37.5 billion) this year. While the banking industry has always spent big on technology, it is doing things a bit differently when it comes to AI.   One striking difference is that banks are looking to hire AI specialists from outside and build their own capabilities, rather than buying a ready solution like they are doing in the case of cloud or mobility. Goldman Sachs, for example, has hired Amazons Charles Elkan to spearhead its AI strategy; JP Morgan has brought Carnegie Mellon University professor, Manuela Veloso on board as head of AI research. The reasons are many and compelling  AI expertise is still very limited; currently available solutions are not standardized; and the technology is so vast and versatile that no two banks want to use it the same way.    The second difference is that banks are deploying the different technologies under the AI umbrella enterprise-wide, in the front, middle and back office. Contrast this with mobility, used mainly in customer experience, or cloud, in infrastructure provisioning. Stuart Russell, in his 2003 book entitled Artificial Intelligence: A Modern Approach, argues that AI is superior to any other technology because it alone is capable of sensing, comprehending, acting and learning. Because AI can sense what is happening, comprehend the event, take informed action in real-time and learn throughout this cycle, it finds unlimited use cases in banking.     The chatbot is the most-adopted AI use case in banks; 39 of the worlds 100 largest banks have it. Figuring right at the top of the peak of inflated expectations in the Gartner Hype Cycle for Artificial Intelligence, 2019, the chatbot has promised more than it has delivered. For instance, it is not quite clear how it has helped customer service in the three to five years it has been around. That being said, the chatbot is here to stay and maybe this is the year that it will start to prove its potential.    In the front office, AI is visible in customer service (chatbot) and sales (making next-best recommendations, for example); in the middle office, machine/deep learning is helping to detect and prevent fraud; in the back office, AI is finding application in identity management, risk mitigation, credit scoring, collections management, etc.    Especially powerful is AIs ability to leverage big data and analytics. Banks are sitting on an enormous pile of highly underutilized data from the last fifty to sixty years. In contrast, their digital-born challengers are putting their (much smaller) data to full use across a spectrum of functions to improve efficiency, experience and engagement.    As data continues to explode  from 4.4 zettabytes in 2013 to 44 zettabytes in 2020  the incumbents analytical disadvantage versus their new competitors will grow, perhaps to a point of no return, unless they find a solution. That solution may be found in AI technologies, such as machine learning and advanced analytics that are capable of handling the volume, variety (structured/unstructured, text/voice/video etc.) and velocity (sporadic, real-time) of big data and turning it into unprecedented value for the banks and their customers.   The third difference of AI is that because it is everywhere, it can help scale digital transformation throughout the bank:          The digital revolution has yielded several indispensable technologies such as mobility, Internet of Things and blockchain. But none can match the ability of AI to be everywhere, and do everything, in the bank.    James Buckley is European head of Finacle, a core banking platform being developed by EdgeVerve Systems, a subsidiary of Infosys ",https://aibusiness.com/document.asp?doc_id=761229&site=aibusiness,Finance
03-02-2020,,Accenture is buying British machine learning startup Mudano," Making its fourth AI acquisition within a year   by Max Smolaks 3 February 2020   Accenture is acquiring Mudano, a data consultancy with customers primarily in the financial services industry, headquartered in London.   The company develops and implements a platform that captures project data - such as daily tasks, meeting notes, resource information and progress reports - and uses machine learning to predict the path of a project.   According to Mudano, this approach can help foresee issues, improve productivity and deliver projects more efficiently.   Financial terms of the deal were not disclosed.    Update: The Sharktower software, developed by the startup, will carry on as a separate business.     Mudano has been working to put artificial intelligence in service of better project outcomes since 2014. It develops a proprietary platform called Sharktower, serving as a front-end for its project optimization efforts.     The company can help with data strategy, data analytics and applied machine learning, placing it somewhere in the middle between a software firm, a data science lab and a consultancy.   Mudano has trademarked its approach as ""Delivery Science"" and says it has been running complex change programs and portfolios with budgets exceeding £100m.    According to FutureScot, the startup received a £2.6m research and development grant from the Scottish government in 2018, after it agreed to open an R&D facility in Edinburgh.   Following the acquisition, Mudano's staff will join Accentures 20,000-strong Applied Intelligence division, where they will help clients in the financial services sector scale their AI efforts.   However Applied Intelligence is not interested in selling software, so Sharktower will continue to exist as a separate business.    The Sharktower business is not a part of the agreed acquisition  and will continue to develop its AI-driven project and portfolio  management technology, George Marcotte, managing director responsible for the Applied Intelligence group in the UK and Ireland, told AI Business.   Sharktower is still available for purchase with a range of enterprise pricing models and extensive support for all customers.   Accenture launched Applied Intelligence in February 2019, looking to combine its expertise across artificial intelligence, data management, analytics and automation. The division has since absorbed AI firms Clarity Insights, Pragsis Bidoop and Analytics8, and now employs a total of 6,000 data scientists, data engineers and AI professionals.   Mudanos focus on helping clients build a data culture aligns perfectly to Accentures applied intelligence strategy,"" Marcotte said. ""By creating a strong data foundation  supported by the right skills, stakeholders and technologies  our clients can transform at speed and scale and fuel real change for their business. ",https://aibusiness.com/document.asp?doc_id=761192&site=aibusiness,Finance
10-01-2020,,Intel enters AI partnership with Chinas largest insurer," Agreement with Ping An Technology will involve a joint laboratory, cooperation on products   by Max Smolaks 10 January 2020   Ping An Technology has announced a strategic collaboration with Intel that will see the two companies establish a joint laboratory, cooperate on products and technology, and form a joint project team in areas of high-performance computing and AI.   Ping An Technology is a subsidiary of Ping An
Insurance, considered to be Chinas largest insurer and the second largest in
the world after Berkshire Hathaway.   ""Partnering with Intel will give Ping An an edge to boost our
cloud technologies and to supercharge our AI-based services and solutions, said
Ericson Chan, CEO of Ping An Technology. We will further strengthen our data
protection with Intel hardware-enabled security in finance and healthcare, two
areas where it is so critical.""     Ping An (literally ""safe and well) was founded in 1988 with headquarters in Shenzhen. Its a holding conglomerate whose subsidiaries mainly deal with insurance, banking, and financial services. In July 2019, the market capitalization of the group stood at $220 billion.   As part of the group, Ping An Technology develops and applies tech across five specific industries: financial services, healthcare, automotive, real estate, and smart city services. It is responsible for the Ping An Cloud, a cloud service developed for internal purposes since 2013, and launched as a commercial offering in 2018.   The division claims to employ more than 23,000 R&D personnel and is responsible for filing more than 6,000 patents to date  more than any other financial institution in China. It will come as no surprise that Ping An Technology considers AI among its core proficiencies  it has implemented AI projects for Chinas Ministry of Human Resources and Social Security, Hong Kong electronic identity program, and Guangfa Bank, among others.   ""The two parties will explore joint development in technology
areas including AI, high performance computing, visual computing and FPGAs
using the full range of Intels data-centric portfolio. We plan to innovate and
support an open ecosystem [across] Ping An Technologys Ping An Cloud,"" said
Rose Schooler, corporate VP for Sales and Marketing Group at Intel. ",https://aibusiness.com/document.asp?doc_id=761168&site=aibusiness,Finance
10-01-2020,,Innodata launches contract data extraction and analytics platform," docAnalytics combines AI capabilities and human expertise   by Max Smolaks 9 January 2020   American data engineering specialist Innodata
has expanded its range of AI-based products with the launch of docAnalytics, a web-based platform that can extract key information from contract
documents with a minimal need for human intervention.   The company says its offering is robust enough to be used in financial services, where complex, lengthy documents often require expensive expert
review.   The existence of docAnalytics was revealed
at the AI Summit New York in December.   We are moving from a service provider into
technology-based solutions, Rahul Singhal, chief product officer at Innodata, told
AI Business at the show. What makes us really different is the fact that we
have a trained AI model, but we also have the subject matter experts.      Innodata is a public company thats has been in the data wrangling business for the past 30 years. It has six global delivery centers, covers the majority of languages spoken around the world, and reported $57.4 million in revenue for 2018.   Its latest product trawls through documents to extract a list of computer-addressable data points that can be immediately integrated into corporate datasets.   docAnalytics combines the work of trained machine learning models and subject matter experts to achieve the highest possible accuracy rates. According to Singhal, in a typical deployment scenario, 60-70 percent of the work is done by algorithms.   Innodata can train and maintain the platform
or leave the management to the customers own data team.   Right now, we are training the model to
spot details in contracts like CSCs, MEDs, master agreements, running an AI
model to extract the data points and then allowing legal users and other users
to run reports or take an API and feed it into downstream systems, Singhal
said.    We found is that there's a lot of need for
automation on the contract side, a lot of our clients have been asking for
that. One of the things that differentiates us from our competition is the
robust taxonomy. We have a 1,000-point taxonomy for these legal documents that
none of our competitors have.   Innodata says the platform is designed for managing financing agreements (such as mortgage agreements and leases), trade documents (including shipping orders, bills of lading, and letters of credit), transactional agreements (spanning ISDA, IFXCO, GMRA, prime brokerage, securities lending, investment management and 23 other document types), and fixed income documents (including bonds, prospectuses and indentures).   While market participants often
invest significant resources in the lengthy process of document creation,
typically involving negotiators, lawyers, tax experts, credit officers and
compliance officers, they have lacked the right tools to make it work. The
result is that when something happens requiring quick thinking  such as a
bankruptcy, default, acquisition, a ratings downgrade, or a net asset value
decline  firms are faced with slow and cumbersome expert reviews, explained Jack
Abuhoff, CEO at Innodata.   With our approach, the experts are
augmented with true digital data and can react quickly to market events and
manage their portfolios of documents proactively. ",https://aibusiness.com/document.asp?doc_id=761166&site=aibusiness,Finance
10-12-2019,,Why Moody's is betting on machine learning," The organization is solving the challenges of financial risk modeling with AI    You might know Moodys Corporation for its credit  rating agency, Moodys Investors Service, trusted by bond investors for opinions on credit risk. But the company, founded way back in 1909, grew ever-larger, and in 2007, Moodys Analytics was established to focus on non-rating activities - including economic research, consulting services and software development. Today, the employees of Moody's Analytics include a large number of machine learning and deep learning experts.   To find out more about the business, we quizzed one such expert, Ashit Talukder, head of machine learning at Moodys Analytics, who previously spent 12 years at NASAs Jet Propulsion Laboratory and served as the CTO of the US Department of Labor.   Q: Most people know Moodys as a credit rating agency. What is Moody's Analytics?   AT: Moodys Analytics provides financial intelligence and analytical tools to help business leaders make better, faster decisions. The machine learning team is based in the Moodys Analytics Accelerator, the firms innovation unit. The Accelerator explores business opportunities adjacent to Moodys core business and rapidly develops prototypes of new solutions by leveraging emerging technology.    Q: How does Moodys Analytics use machine learning technologies?   Moodys Analytics has been using technology for analytical 
purposes for many years. We pioneered the use of statistical analytics models 
for risk assessment. More recently, we began strategically leveraging machine 
learning and artificial intelligence across our solutions.    An early focus area was to use artificial intelligence and machine learning to extract knowledge and structured information from unstructured data, such as text, images, video and audio. We observed that unstructured data analysis in finance (as it is in many other domains) is mostly a manual process. These highly manually processes result in costly, ineffective solutions and workflows while limiting the amount of data that can be analyzed and consumed. The result is often that critical information is overlooked due to the finite number of person-hours available. Recognizing that fundamental issue has driven many of our AI and ML initiatives. In other words, we are using AI and ML at Moodys Analytics to enable faster, data-driven decisions at scale.    To that end, we have launched intelligent products that augment 
the role of the analyst in the data gathering or data normalization process. At 
AI Summit 2018 we launched QUIQspread, an intelligent, automated, financial spreading tool that 
standardizes customer information from income statements, balance sheets and 
other financial documents    Additionally, we offer Compliance 
Catalyst with Adverse 
Media which supports compliance risk assessment in 
client onboarding, Know Your Customer (KYC) and enhanced due-diligence activities. 
We have also started to use machine learning for better financial risk modeling 
and default prediction from financial statements.   Q: How difficult is it to extract information from unstructured data sources, like social media posts or video? Why is this information valuable?   Machine learning has been used for analytics and decision-making from structured data for over two decades. By structured data, I am referring to data in machine readable, row-column formats, in the form of mostly numerical and/or categorical data. Traditional machine learning models (such as logistic regression, decision-trees, SVMs, etc.) are well suited to process structured data. Until recently, the ability of ML to process unstructured data, such as text, images was very limited.    With the advent of deep learning, AI ML models can now effectively process raw unstructured data, without requiring manually crafted features (which are often only partly optimal). Now, deep learning Convolutional Neural Networks can process image data for image classification and object identification; Recurrent Neural Networks and Long-Short-term Memory (LSTM) neural networks can do natural language processing (NLP) tasks by reading text passages and using context to understand sentiment, identify key entities and relations between them.    Now it is easier than ever to extract information from unstructured data sources but this is still a problem that is not fully solved. First, text information from social media and news is voluminous, complex, very noisy, with a high degree of variability in expression, and its nontrivial to fully understand context due to the high degree of variability and nuances in human language. So, while Natural Language Processing (NLP) has improved significantly, more robust Natural Language Understanding (NLU) has still a way to go in terms of comprehension and generalizability across domains and applications. So, in short, its actually still a significant endeavor to extract and comprehend information from unstructured sources.   The information available in unstructured data, such as news, 
company reports, transcripts of meetings and announcements, and social media 
often complements the information available in structured data (such as 
numerical data in financial statements). Furthermore, the information from 
unstructured data is more recent, and often offers real-time insights into 
events, changes related to organizations and people, that could provide timely 
insights into early warning indicators and risk models, thereby enabling faster 
insights and predictions than was previously possible with more traditional 
data. This, of course, assumes that the AI models can extract the key nuggets 
of relevant information from the available massive, diverse data sources in a 
timely manner. Our AI-driven solutions and products demonstrate that with the 
right models, and training data, we can find the needle in the haystack for obtaining 
valuable, timely insights from unstructured data to better understand and assess different types of risk.   Q: In your career, you spent two years working as CTO of the US Department of Labor. How do you rate the understanding of machine learning in the public sector?    The public sector has traditionally been ahead of the curve in 
terms of R&D of emerging technologies. Federal agencies such as DARPA, 
ARPA, NSF, NIST, NASA, NIH have been spearheading investments in basic and 
R&D around new technologies for decades, such as networking and the internet 
(the ARPAnet funded by DARPA ultimately led to the invention of the internet), 
biotech, healthcare, robotics, AI, and machine learning, and more recently 
quantum computing. NIST has had a Quantum computing program for more than a 
decade, while industry has only recently used Quantum computing. DARPA 
initiated robotics and AI research, through R&D investments in the 90s and 
2000-2005 timeframes, through programs in the 1998-2004 timeframe such as 
Software Defined Robotics (SDR), Robotics Vision 2020, the DARPA Grand 
Challenge that led to the transition of autonomous vehicles, and AI-enabled 
computer vision into industry.    Recently, the private sector has led the use of Machine Learning 
and AI in operational settings (i.e. beyond R&D), once the basic R&D 
issues in AI, ML were resolved through federal funding and deep learning proved 
its mettle on research problems. Part of the reason for this is that the 
private sector is more risk-tolerant in application of emerging technology to 
solve new problems and faces fewer regulations. Secondly, the public sector 
deals with legacy systems and non-digital processes that present a hurdle to 
adoption of AI. This issue is less prevalent in the private sector, where Web 
2.0 (websites that rely on user-generated content) companies employing modern 
systems and digital data, already exist. Additionally, the use of AI, ML in 
commercial settings is broader, in areas such as retail and e-commerce 
(recommendation systems), healthcare (insurance modeling and prediction), finance 
(risk analytics and prediction), and others.    Now with a better understanding of the prevalence and impact of 
AI, the U.S. government has realized that policies that take ethical 
considerations into account need to be put in place to accommodate a future 
where AI plays a central role in shaping the future of society, industry and 
science. New strategic planning committees are being established in the public 
sector to help guide policies and investments in an AI-driven world.   Q: You also spent more than a decade at NASAs Jet Propulsion Laboratory. What are the key applications of machine learning in the aerospace industry?   I thoroughly enjoyed my time at NASAs Jet 
Propulsion Laboratory. The aerospace industry and the space research agencies 
(NASA and its subsidiaries) have been employing machine learning in space and 
aerospace applications since the 90s. JPL had an AI group that developed novel 
rule-based expert systems for spacecraft resource allocation, and a computer 
vision group and ML group that designed computer vision and ML systems for 
robotic planetary navigation and exploration. At JPL, through funding from the 
DARPA Robotics Vision 2020 Research program, I co-led the development of the 
first real-time computer vision solution capable of detecting and tracking 
moving objects from moving autonomous robots in 2002; this body of work has 
been cited more than 850 times. We also worked on distributed ML solutions for 
IoT earth observing sensor networks in the 2005 timeframe. A lot of R&D 
work around autonomous systems and AI at NASA and aerospace agencies was 
patented, and spun-off into the commercial sector.   Q: Moodys Analytics is currently expanding its data science team. How hard is it to find the people with the skills the organization requires?   We are always on 
the lookout for talented data scientists! Given the potential for AI, ML, many 
organizations are vying for the unique combination of talent that can both 
understand and implement custom AI ML solutions for practical applications. We 
are particularly looking for individuals that have a thorough grasp of the 
theoretical aspects of deep learning, but also understand how the implementation 
of AI solutions works in practice and have the data engineering skills needed 
to roll out custom applications.    Deep learning is 
still nascent and in its infancy. However, my team, based in the Moodys Analytics 
Accelerator, offers a unique environment where we span applied AI, ML R&D 
and product development experience, and the opportunity to spread ones wings 
in terms of understanding business and product lifecycles while working on exciting, 
cutting-edge AI technologies.     Ashit Talukder is head of machine learning at Moody' Analytics. Meet Ashit and the Moody's team at the AI Summit New York, December 11-12 ",https://aibusiness.com/author.asp?section_id=796&doc_id=761144,Finance
29-11-2019,,ML and NLP-powered services that give banks a competitive edge," by Karen Krivaa, GigaSpaces 29 November 2019   Nimble fintech start-ups and established tech giants like Amazon and Alibaba are upending retail banking. Traditional banks need to provide the best financial terms, and superior customer experiences to stay in the game.    They can fight back by deploying deep learning solutions armed with NLP to respond faster to customer inquiries, proactively recommend services, analyze contracts quicker and improve their ability to comply with regulations. Here are just a few examples:     Chatbots armed with NLP can make upsell and cross-sell suggestions based on a customers current activities combined with their personal banking history. For example, Toronto based Sun Life has created the virtual assistant, Ella, to inform customers of an upcoming change in the status of their account such as Your childs benefits are about to expire. An automated service can also use NLP to provide human call center agents with personalized recommendations for new service offerings that is derived from a textual analysis of the latest customer interactions combined with their loan, mortgage, and investment history.     Customer service representatives can leverage deep learning solutions including NLP to reduce the average call handling time. NLP techniques can analyze text to understand the customers intent to route the call to the most relevant agent. By analyzing previous requests and responses using text classification, smart agent assistants (similar to those utilized at FinanzInformatik), can present the five most similar cases in milliseconds.  Bots can also be used to use text to speech conversion to respond in a way that is closest to a human voice. Bank of America's bot named Erica has assisted one million users in three months and can provide information about specific transactions with a particular merchant, and the current amount of a customers total credit and debt.     An investment firm can build a personalized investment strategy by analyzing patterns in how customers spend, invest, or make financial decisions based on an analysis of their transaction history using NLP. The software can then perform sentiment analysis using NLP to scan news outlets and social media such as CNN, BBC, USA Today, NY Times, etc. to predict future price movements for the relevant investments before making a specific recommendation.     Time consuming, competitive mundane work can be eliminated by using a model utilizing NLP to interpret, record, and correct digitized contracts at high speed. The accuracy of the models outcome is remarkably high because of the repetitive nature of contracts. COIN, machine learning software that utilizes NLP, launched by JP Morgan Chase, is able to extract 150 relevant attributes from 12,000 annual commercial credit agreements in seconds. Previously, the banks legal team spent around 360,000 hours manually reviewing commercial loan agreements.      Financial advisory services are highly regulated and financial firms are required to monitor the performance of their advisors to ensure compliance. A customer complaint, such as charging a fee that was not disclosed upfront, could attract a fine or a bad regulatory rating from supervisory agencies. NLP software can run through several millions of incoming customer service requests and categorize text to populate a table of interactions that should be reviewed by the compliance team. In addition, NLP can be used to prove that banks are meeting GDPR regulations by deleting personal data as per customer requests.   Financial institutions can provide superior customer experiences by deploying machine learning and deep learning  solutions that include NLP. There are, however, several factors that can create a barrier for running machine learning models in production.   Models need to be fed with fresh and historical data reliably and continuously in order to be retrained. Bottlenecks ingesting and processing data can slow down models and sabotage their results.   A distributed in-memory computing platform can act as a unified data speed layer to operationalize models by minimizing data movement to practically zero while leveraging the speed of RAM. The platform can support high ingestion rates of millions of IOPs, store any type of data (structured, unstructured and semi-structured) and seamlessly run analytics models with extremely low latency.   Machine Learning and deep learning armed with NLP can improve the efficiency and effectiveness of banking services. By using technology to accelerate the process of storing, moving and analyzing data, personalized services are becoming  even more relevant and effective, providing a significant differentiator for financial institutions and a better customer experience for everyone.    Karen Krivaa is VP Global Marketing at GigaSpaces Technologies, a developer of in-memory computing platforms. ",https://aibusiness.com/document.asp?doc_id=761139&site=aibusiness,Finance
01-11-2019,,CaseWare launches an AI-driven platform for the audit industry," Promises more audits completed in less time   by Max Smolaks 1 November 2019   Canadian accounting software specialist
CaseWare has launched an AI-driven product designed specifically to simplify
the often-grueling process of financial audit.   The platform, called AnalyticsAI, promises to grant auditors and business service professionals access to advanced analytics based on machine learning algorithms, without the need for data science skills  which are currently in short supply.   Were bringing
this ground-breaking technology to market to address a new reality:
conventional auditing processes simply cannot keep pace with the volume of data
generated in todays digital business environment, said Matt Dodds, general
manager for CaseWare IDEA.   Weve
designed AnalyticsAI so anyone on the audit team can use it to easily spot
exceptions in client data that warrant further investigation and indicate areas
of higher risk.   CaseWare
has been developing accounting software for the past 30 years and says the adoption
of AI is poised to revolutionize the industry.   AnalyticsAI can import trial balance and transaction data from multiple accounting packages
and features a data reliability checklist and automatic
data reconciliation tools.   To identify accounting anomalies, the software
tests entire datasets at once,
without breaking them down into subsets. Since the system is based on machine
learning, it can identify anomalies that are outside of the parameters of the
audit.   AnalyticsAI can then feed the results directly
into any working papers solution - CaseWare
says this simplifies regulatory compliance, since analytics is integrated right
into the engagement workflow.   Data is
the driver of everything we do, so its an exciting time for us in that were
shaping the future of analytics in the audit industry. The most rewarding part
of this initiative to drive transformation will occur when firms look back and
wonder how they used to work any other way, said Ross Hampton, head of business
development for the Americas at CaseWare. ",https://aibusiness.com/document.asp?doc_id=761120&site=aibusiness,Finance
23-08-2019,,The need to know: Trust anchors," The cost of getting AI wrong extends beyond the financialslost revenue, fines from compliance failuresto reputational, brand, and ethical concerns   by Martin Sokalski 20 August 2019   Key business decisions at scale have a
determining effect on success; as an example, should we approve a credit card
for a customer?   Among the decisions for each customer: the annual percentage rate, the spending limit, and a long list of other factors. Machine learning models are typically making these decisions for millions of customers.   In a very real sense, given the scale, the business is in the hands of a handful of smart data scientistsand the machines they build and trainusing ground truth created from historical loan data.     Most algorithms today are relatively simple
and deterministic: they produce the same output from a predetermined set of
states and a fixed number of rules. The approaches for evaluating them for
validity and integrity are largely established and adopted. In fact, in our
estimation, over 80 percent of the leading practices needed to maintain their
accuracy and effectiveness are known.    Think of expert systems in manufacturing.
Think of actuarial science that uses deterministic rules or decision tables in
insurance. Think of robotic process automation in financial services.   It isnt that hard to determine whether the
conclusions they reach are acceptableand sound and scalable supervision is
relatively easy.    These rules can get very complex,
especially when the number of attributes (also known as features, or variables)
in the data or the number of records increases.    Machine learning and deep learningand
other types of AIare creatures of a different kind. They are trained to learn
from data (commonly referred to as ground truth) instead of being explicitly
programmed, which means they can understand-learn-uncover the nuances and the
patterns in the data, they can handle a very large set of attributes, and are
often significantly more complex in how they do what they do.    Think of training a prediction model from a
set of a million past loan applications, which in turn uses 100 attributes.
Think of detecting a tumor from a million MRI images. Think of classifying
emails. Once trained and evaluated, these models can be provided with new or
unseen data from which they can make predictions. They are probabilistic in
nature and respond with a degree of confidence.    While all of these aspects are good, it can
be unclear what the models are doing: what they learn, particularly when
employing opaque deep learning techniques such as neural nets, how they will
behave, or whether they will develop unfair bias over time as they continue to
evolve. Thats why understanding which attributes in the training data
influence the models predictions has become very important.     Lets take a closer look at a potential
problem for the business leader in the loan division of a big financial firm.    If an error hides within an algorithm (or
the data feeding or training the algorithm), it can influence the integrity and
fairness of the decision made by the machine. This could include adversarial
data or data masking as ground truth.    The business leaders are on the hook for
preserving the brand reputation for the firm, even as the AI models
increasingly make decisions that might not be understood or in line with
corporate policies, corporate values, guidelines, and the publics
expectations. Multiply these issues by the number of algorithms the loan
division is utilizing. This is when trust weakens or actually evaporates.     A number of techniques, including those
based on renormalization group theory, have been proposed. As models
across AI tasksincluding computer vision, speech recognition, and natural
language processing become more sophisticated and autonomous, they take on a
higher level of risk and responsibility. When left untrained for long periods,
things can go awry: runtime bias creep, concept drift, and issues such as
adversarial attacks can compromise what these models learn. Imagine compromised
MRI scans or traffic lights being manipulated in a smart city.    Continuous-learning algorithms also
introduce a new set of cybersecurity considerations. Early adopters are still
grappling with the magnitude of risks presented by these issues on the
business.    Among the risks are adversarial attacks
that hit the very foundation of these algorithms by poisoning the models or
tampering with training data sets, potentially compromising privacy, the user
experience, intellectual property, and any number of other key business
aspects. Consider the impact on lives or an environment of an adversarial
attack in medical devices or industrial control systems. Tampering with data
could disrupt consumer experiences by providing inappropriate suggestions in
retail or financial services. Such attacks might ultimately erode the
competitive advantage that the algorithms were intended to create.   With complex, continuous-learning algorithms, humans need to know more than just the data or attributes and their respective weights to fully realize the implications of the AI getting it wrong or going rogue; they need to understand aspects such as the context and intended purpose under which the model was developed, who trained them, provenance of the data and any changes made to it, and how the models were (and are) served and protected. And they need to understand what questions to ask and what key indicators to look for around an algorithms integrity, explainability, fairness, and resilience.    This
opinion was originally published as part of Controlling
AI, a KPMG research campaign investigating responsible design and
operation of AI programs.   Martin
Sokalski is a global leader for KPMGs Emerging Technology Risk practice. He
helps organizations around the globe embrace the art of the possible, enabled
by emerging technologies like artificial intelligence, by facilitating
ideation, innovation, and responsible adoption.    Martin
regularly speaks at conferences and contributes to thought leadership on
artificial intelligence, digital transformation, and emerging technologies. He
believes that adoption of AI at scale is currently inhibited by lack of trust
and transparency, explainability, and unintended bias and aims to work with
industry leaders to solve for that challenge. ",https://aibusiness.com/document.asp?doc_id=761022&site=aibusiness,Finance
